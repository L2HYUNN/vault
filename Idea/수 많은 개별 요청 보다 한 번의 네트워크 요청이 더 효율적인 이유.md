많은 수의 작은 파일을 개별적으로 요청하는 것이 하나의 파일로 요청하는 것보다 네트워크 오버헤드를 증가시키고, 로딩 속도를 저하시킬 수 있는 이유를 네트워크 이론과 논리를 바탕으로 설명하겠습니다.

### 1. HTTP 요청/응답의 오버헤드
각 HTTP 요청과 응답은 실제 데이터 외에도 추가적인 오버헤드를 동반합니다. 주요 오버헤드 요소는 다음과 같습니다:

- **TCP 연결 설정**: 각 요청에 대해 클라이언트와 서버는 TCP 연결을 설정해야 합니다. 이 과정에는 TCP 핸드셰이크(3-way handshake) 과정이 필요하며, 이는 왕복 시간(RTT, Round Trip Time)을 소모합니다.
- **HTTP 헤더**: 각 요청과 응답은 헤더 정보를 포함합니다. 헤더는 필수적인 메타데이터를 포함하지만, 실제 데이터와는 별개로 추가적인 바이트를 차지합니다.
- **TLS 핸드셰이크**: HTTPS를 사용하는 경우, 각 연결은 TLS 핸드셰이크를 수행하여 보안 연결을 설정해야 합니다. 이는 추가적인 왕복 시간과 오버헤드를 야기합니다.

이러한 오버헤드가 많아지면 네트워크 효율이 떨어지고, 페이지 로딩 시간이 증가합니다.

### 2. 브라우저의 병렬 요청 제한
브라우저는 동일한 도메인에 대해 병렬로 요청할 수 있는 최대 연결 수에 제한을 둡니다. HTTP/1.1의 경우 일반적으로 도메인당 최대 6개의 연결을 허용합니다. 이 제한 때문에, 많은 파일을 개별적으로 요청할 경우 병목현상이 발생할 수 있습니다.

- **연결 수 제한**: 병렬 요청의 수가 제한되어 있으므로, 나머지 요청들은 큐에서 대기해야 합니다. 이는 전체 로딩 시간을 증가시킵니다.

### 3. TCP 연결의 초기 전송 속도
TCP 연결은 처음에 전송 속도를 천천히 시작하고, 점진적으로 증가시키는 "Slow Start" 알고리즘을 사용합니다. 많은 수의 작은 파일을 요청할 때, 각 파일에 대해 새로운 TCP 연결을 설정하면, 각 연결이 낮은 전송 속도로 시작하여 성능이 저하될 수 있습니다.

### 4. 캐싱 효율성
큰 파일 하나로 번들링하면, 그 파일이 캐싱되어 이후 요청 시 재사용될 가능성이 높습니다. 그러나 많은 작은 파일로 개별적으로 요청하면, 각 파일의 캐시 유효성을 개별적으로 관리해야 하므로 캐싱 효율성이 떨어질 수 있습니다.

### 비교: 하나의 큰 파일 요청
- **한 번의 TCP 연결 설정**: 단 하나의 TCP 연결을 설정하면 되므로, TCP 핸드셰이크 오버헤드가 한 번만 발생합니다.
- **한 번의 HTTP 헤더**: 요청과 응답에서 헤더 오버헤드가 한 번만 발생합니다.
- **효율적인 TCP 전송 속도**: TCP 연결이 한 번만 설정되면, "Slow Start" 알고리즘의 영향을 덜 받고 빠른 속도로 데이터 전송이 가능합니다.
- **캐싱의 단순화**: 큰 파일 하나를 캐싱하면, 다음 요청에서 빠르게 재사용할 수 있습니다.

### 결론
많은 수의 작은 파일을 개별적으로 요청하는 것이 네트워크 오버헤드를 증가시키고 로딩 속도를 저하시키는 이유는 TCP 연결 설정의 오버헤드, 브라우저의 병렬 요청 제한, TCP의 "Slow Start" 알고리즘, 그리고 캐싱 효율성 때문입니다. 따라서, 여러 파일을 하나의 번들로 묶어서 전송하는 것이 네트워크 성능을 최적화하는 데 효과적입니다.

**Q1:** HTTP/2 프로토콜은 이러한 문제를 어떻게 해결하나요?

**Q2:** 번들링 외에 네트워크 성능을 최적화할 수 있는 다른 방법은 무엇인가요?

**Q3:** 자산을 압축하여 전송할 때 사용하는 일반적인 방법은 무엇인가요?